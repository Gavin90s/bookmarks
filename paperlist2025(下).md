#### [Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data](https://assets.amazon.science/79/5d/e64b592c479a85d046cda12a2bb9/learning-with-less-knowledge-distillation-from-large-language-models-via-unlabeled-data.pdf)
![image](https://github.com/user-attachments/assets/a80e2902-cccd-4d84-acfd-5f39d01dfce1)
````
Learning with Less computational resources and less data for Knowledge Distillation from LLMs.
LLKD 使用自适应样本选择(adaptive sample selection)方法, 挑选teacher认为置信度高(high confidence)，
但student判断到不确定性高(high uncertainty)的样本。
````

#### [DIRECT REASONING OPTIMIZATION: LLMS CAN REWARD AND REFINE THEIR OWN REASONING FOR OPEN-ENDED TASKS](https://arxiv.org/pdf/2506.13351)

#### [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://www.arxiv.org/pdf/2506.03143)

#### [Keeping Humans in the Loop:Human-Centered Automated Annotation with Generative AI](https://arxiv.org/pdf/2409.09467)

#### [LLMS GET LOST IN MULTI-TURN CONVERSATION](https://arxiv.org/pdf/2505.06120)

#### [Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V](https://arxiv.org/pdf/2310.11441)

#### [IMPROVE VISION LANGUAGE MODEL CHAIN-OFTHOUGHT REASONING](https://arxiv.org/pdf/2410.16198)

#### [Group Sequence Policy Optimization](https://arxiv.org/pdf/2507.18071)

#### [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)

#### [Qwen2.5-Omni Technical Report](https://arxiv.org/pdf/2503.20215)

#### [MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains](https://arxiv.org/pdf/2407.18961)
https://github.com/apple/axlearn/tree/main/docs/research/mmau

#### [GUI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/pdf/2501.12326)

#### [AppAgentX: Evolving GUI Agents as Proficient Smartphone Users](https://arxiv.org/pdf/2503.02268)
https://github.com/Westlake-AGI-Lab/AppAgentX/blob/main/explor_auto.py

#### [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/pdf/2507.14447)

#### [KIMI K2: OPEN AGENTIC INTELLIGENCE](file:///Users/bytedance/Downloads/tech_report%20.pdf)

#### [Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models](https://arxiv.org/pdf/2501.11873)

#### [Qwen3 Technical Report](https://arxiv.org/pdf/2505.09388)

#### [DIRECT REASONING OPTIMIZATION: LLMS CAN REWARD AND REFINE THEIR OWN REASONING FOR OPEN-ENDED TASKS](https://arxiv.org/pdf/2506.13351)

#### [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://www.arxiv.org/pdf/2506.03143)

#### [Keeping Humans in the Loop: Human-Centered Automated Annotation with Generative AI](https://arxiv.org/pdf/2409.09467)

#### [LLMS GET LOST IN MULTI-TURN CONVERSATION](https://arxiv.org/pdf/2505.06120)

#### [Rewriting Pre-Training Data Boosts LLM Performance in Math and Code](https://arxiv.org/pdf/2505.02881)

#### [UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis](https://arxiv.org/pdf/2504.11257)

#### [Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming](https://arxiv.org/pdf/2408.16725)

#### [Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://arxiv.org/pdf/2508.09736)

#### [VERIGUI: VERIFIABLE LONG-CHAIN GUI DATASET](https://arxiv.org/pdf/2508.04026)

#### [Lost in Transmission:When and Why LLMs Fail to Reason Globally](https://arxiv.org/pdf/2505.08140)

#### [UI-Venus Technical Report: Building High-performance UI Agents with RFT](https://arxiv.org/pdf/2508.10833)

#### [ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation](https://arxiv.org/pdf/2407.06135)

#### [MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text](https://arxiv.org/pdf/2210.02928)

#### [Speculative Decoding Reimagined for Multimodal Large Language Models](https://arxiv.org/pdf/2505.14260)

#### [Mixed Preference Optimization: A Two-stage Reinforcement Learning with Human Feedbacks](https://arxiv.org/pdf/2403.19443)

#### [Token Level Routing Inference System for Edge Devices](https://arxiv.org/pdf/2504.07878)

#### [RL’S RAZOR: WHY ONLINE REINFORCEMENT LEARNING FORGETS LESS](https://arxiv.org/pdf/2509.04259)

#### [RLP: Reinforcement as a Pretraining Objective](https://arxiv.org/pdf/2510.01265)
````
RLP 把“让模型自己写 CoT→看是否更好预测下一词”作为自监督奖励，首次把强化学习的探索机制提前到预训练阶段，显著且高效地为大模型注入推理能力，为“预训练即推理”提供了新范式。
````
<img width="1950" height="920" alt="image" src="https://github.com/user-attachments/assets/bb8ee8b8-f3dd-4915-9d4b-787e3b0bbe44" />

