#### [Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data](https://assets.amazon.science/79/5d/e64b592c479a85d046cda12a2bb9/learning-with-less-knowledge-distillation-from-large-language-models-via-unlabeled-data.pdf)
![image](https://github.com/user-attachments/assets/a80e2902-cccd-4d84-acfd-5f39d01dfce1)
````
Learning with Less computational resources and less data for Knowledge Distillation from LLMs.
LLKD 使用自适应样本选择(adaptive sample selection)方法, 挑选teacher认为置信度高(high confidence)，
但student判断到不确定性高(high uncertainty)的样本。
````

#### [DIRECT REASONING OPTIMIZATION: LLMS CAN REWARD AND REFINE THEIR OWN REASONING FOR OPEN-ENDED TASKS](https://arxiv.org/pdf/2506.13351)

#### [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://www.arxiv.org/pdf/2506.03143)

#### [Keeping Humans in the Loop:Human-Centered Automated Annotation with Generative AI](https://arxiv.org/pdf/2409.09467)

#### [LLMS GET LOST IN MULTI-TURN CONVERSATION](https://arxiv.org/pdf/2505.06120)

#### [Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V](https://arxiv.org/pdf/2310.11441)

#### [IMPROVE VISION LANGUAGE MODEL CHAIN-OFTHOUGHT REASONING](https://arxiv.org/pdf/2410.16198)

#### [Group Sequence Policy Optimization](https://arxiv.org/pdf/2507.18071)

#### [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)

#### [Qwen2.5-Omni Technical Report](https://arxiv.org/pdf/2503.20215)

#### [MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains](https://arxiv.org/pdf/2407.18961)
https://github.com/apple/axlearn/tree/main/docs/research/mmau

#### [GUI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/pdf/2501.12326)

#### [AppAgentX: Evolving GUI Agents as Proficient Smartphone Users](https://arxiv.org/pdf/2503.02268)
https://github.com/Westlake-AGI-Lab/AppAgentX/blob/main/explor_auto.py

#### [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/pdf/2507.14447)
