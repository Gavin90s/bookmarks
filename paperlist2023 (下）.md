#### [SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS](https://openreview.net/pdf?id=1PL1NIMMrw)
使用称为self-consistency的decoding strategy代替naive greedy decoding 逻辑推理能力。
<img width="676" alt="image" src="https://github.com/Gavin90s/bookmarks/assets/8350994/dd53305c-0ad6-45bf-9a56-5820aa16965f">

#### [Improving In-Context Few-Shot Learning via Self-Supervised Training](https://arxiv.org/pdf/2205.01703.pdf)
在预训练之后，下游任务微调之前，使用自监督学习(self-supervision) 添加一些预训练任务，可以提升模型的 In-Context Few-Shot Learning。 
<img width="972" alt="image" src="https://github.com/Gavin90s/bookmarks/assets/8350994/1158e1f5-8341-46dd-b8f7-2ef876312a14">

#### 提取句向量的transformer (sentence transformer)
sentence transformer（bi-encoders）
![image](https://github.com/Gavin90s/bookmarks/assets/8350994/ca5c6084-7355-42ff-b8cf-a0c3a0391ba3)

交叉编码器（cross-encoder）
![image](https://github.com/Gavin90s/bookmarks/assets/8350994/ff9e2e59-b092-47ab-9745-a37e02296d1


用Cross-Encoder对所有挖掘出的段落进行分类, 使用Cross-Encoder帮助Bi-Encoder挖掘困难负例。
