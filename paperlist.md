# paperlist

MULTI-HEAD MONOTONIC CHUNKWISE ATTENTION FOR ONLINE SPEECH
https://arxiv.org/pdf/2005.00205.pdf

Joint Speech Recognition and Speaker Diarization via Sequence Transduction
https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1943.pdf

Towards Fast and Accurate Streaming End-To-End ASR

JOINT PHONEME-GRAPHEME MODEL FOR END-TO-END SPEECH RECOGNITION
https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45885a679869bf40528dcf46cfd795a3003eeb5e.pdf

Conformer: Convolution-augmented Transformer for Speech Recognition
https://arxiv.org/pdf/2005.08100.pdf

ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context
https://arxiv.org/pdf/2005.03191.pdf

DELIBERATION MODEL BASED TWO-PASS END-TO-END SPEECH RECOGNITION
https://arxiv.org/pdf/2003.07962.pdf

Large-Scale Multilingual Speech Recognition with a Streaming End-to-End Model
https://arxiv.org/pdf/1909.05330.pdf

EFFICIENT KEYWORD SPOTTING USING DILATED CONVOLUTIONS AND GATING
https://arxiv.org/pdf/1811.07684.pdf

A SPELLING CORRECTION MODEL FOR END-TO-END SPEECH RECOGNITION
https://arxiv.org/pdf/1902.07178.pdf

ASR Error Correction with Augmented Transformer for Entity Retrieval
https://assets.amazon.science/b1/08/ff1fed594cf9803db0253c92c9dd/asr-error-correction-with-augmented-transformer-for-entity-retrieval.pdf

LEARNING ASR-ROBUST CONTEXTUALIZED EMBEDDINGS FOR SPOKEN LANGUAGE UNDERSTANDING
https://arxiv.org/pdf/1909.10861.pdf

Using Confusion Networks for Speech Summarization
https://dl.acm.org/doi/pdf/10.5555/1857999.1858005

https://drive.google.com/file/d/1YRwQ9S2PmRCp5WBcNufAhcqIKtmREkfn/view

https://yuque.antfin-inc.com/docs/share/97cc89d0-b95c-40fe-8543-853c37c2a143?#

https://github.com/LeeSureman/Flat-Lattice-Transformer/blob/master/V1/add_lattice.py

https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/slides/tutorial-part5-pretraining.pdf

Pretraining by Backtranslation for End-to-end ASR in Low-Resource Settings
https://arxiv.org/pdf/1812.03919.pdf

Self-training and Pre-training are Complementary for Speech Recognition
https://arxiv.org/pdf/2010.11430.pdf

ITERATIVE PSEUDO-LABELING FOR SPEECH RECOGNITION
https://arxiv.org/pdf/2005.09267.pdf

wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
file:///Users/zhuozhu/Desktop/2006.11477.pdf

SYNTH2AUG: CROSS-DOMAIN SPEAKER RECOGNITION WITH TTS SYNTHESIZED SPEECH
https://arxiv.org/pdf/2011.11818.pdf

Self-training and Pre-training are Complementary for Speech Recognition
https://arxiv.org/pdf/2010.11430.pdf

Rethinking the Value of Labels for Improving Class-Imbalanced Learning
https://arxiv.org/abs/2006.07529#:~:text=Specifically%2C%20we%20confirm%20that%20(1,that%20imbalanced%20labels%20are%20not
Semi-Supervised Speech-Language Joint Pre-Training for Spoken Language Understanding
https://arxiv.org/abs/2010.02295

https://github.com/google/mentornet/blob/master/TRAINING.md
Unsupervised Cross-lingual Representation Learning for Speech Recognition
https://arxiv.org/abs/2006.13979

Meta Pseudo Labels
https://arxiv.org/abs/2003.10580

Learning From Noisy Labels By Regularized Estimation Of Annotator Confusion
https://arxiv.org/pdf/1902.03680.pdf

Learning from Noisy Labels with Deep Neural Networks: A Survey
https://arxiv.org/pdf/2007.08199.pdf

VQ-WAV2VEC: SELF-SUPERVISED LEARNING OF DISCRETE SPEECH REPRESENTATIONS
https://arxiv.org/pdf/1904.05862.pdf

CTC-based AM for ASR总结
https://www.jianshu.com/p/68eb6c377bda

UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data
https://arxiv.org/pdf/2101.07597.pdf

Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling
https://arxiv.org/abs/1703.00096

SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition
https://arxiv.org/abs/1904.08779

Improved Mask-CTC for Non-Autoregressive End-to-End ASR
https://arxiv.org/abs/2010.13270

Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict
https://arxiv.org/abs/2005.08700

Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning
https://arxiv.org/abs/1609.06773

Research on Modeling Units of Transformer Transducer for Mandarin Speech Recognition
https://arxiv.org/pdf/2004.13522.pdf

Automatic Spelling Correction with Transformer for CTC-based End-to-End Speech Recognition
https://arxiv.org/pdf/1904.10045.pdf

MediaSpeech: Multilanguage ASR Benchmark and Dataset
https://arxiv.org/pdf/2103.16193.pdf

Convolutional Dropout and Wordpiece Augmentation for End-to-End Speech Recognition
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9415004

FRILL: A Non-Semantic Speech Embedding for Mobile Devices
https://arxiv.org/pdf/2011.04609.pdf

STATE-OF-THE-ART SPEECH RECOGNITION WITH SEQUENCE-TO-SEQUENCE MODELS
https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/74a8df45b9583e193e6cf8e156dfba9b73c33a0c.pdf

Leveraging Pre-trained Checkpoints for Sequence Generation Tasks
https://arxiv.org/pdf/1907.12461.pdf
https://huggingface.co/blog/warm-starting-encoder-decoder

SELF-ATTENTION ALIGNER: A LATENCY-CONTROL END-TO-END MODEL FOR ASR USING SELF-ATTENTION NETWORK AND CHUNK-HOPPING

W2V-BERT: COMBINING CONTRASTIVE LEARNING AND MASKED LANGUAGE MODELING FOR SELF-SUPERVISED SPEECH PRE-TRAINING

USING SYNTHETIC AUDIO TO IMPROVE THE RECOGNITION OF OUT-OF-VOCABULARY WORDS IN END-TO-END ASR SYSTEMS

CONTRASTIVE SEMI-SUPERVISED LEARNING FOR ASR

DEVELOPING REAL-TIME STREAMING TRANSFORMER TRANSDUCER FOR SPEECH RECOGNITION ON LARGE-SCALE DATASET

∆LM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders

AN ASYNCHRONOUS WFST-BASED DECODER FOR AUTOMATIC SPEECH RECOGNITION

CONVOLUTIONAL DROPOUT AND WORDPIECE AUGMENTATION FOR END-TO-END SPEECH RECOGNITION

Multitask Training with Text Data for End-to-End Speech Recognition

MPROVING STREAMING AUTOMATIC SPEECH RECOGNITION WITH NON-STREAMING MODEL DISTILLATION ON UNSUPERVISED DATA

QUARTZNET: DEEP AUTOMATIC SPEECH RECOGNITION WITH 1D TIME-CHANNEL SEPARABLE CONVOLUTIONS

FRILL: A Non-Semantic Speech Embedding for Mobile Devices

Shrinking Bigfoot: Reducing wav2vec 2.0 footprint*

A SYSTEMATIC COMPARISON OF GRAPHEME-BASED VS. PHONEME-BASED LABEL UNITS FOR ENCODER-DECODER-ATTENTION MODELS

Comparing CTC and LFMMI for out-of-domain adaptation of wav2vec 2.0 acoustic model

Efficiently Fusing Pretrained Acoustic and Linguistic Encoders for Low-resource Speech Recognition

Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling
http://research.baidu.com/Public/uploads/5ac03f0ebc39f.pdf

Vectorized Beam Search for CTC-Attention-based Speech Recognition
http://research.baidu.com/Public/uploads/5ac03f0ebc39f.pdf

IMPROVING STREAMING AUTOMATIC SPEECH RECOGNITION WITH NON-STREAMING MODEL DISTILLATION ON UNSUPERVISED DATA
https://arxiv.org/pdf/2010.12096.pdf

Multitask Training with Text Data for End-to-End Speech Recognition
https://arxiv.org/pdf/2010.14318.pdf

ITERATIVE PSEUDO-LABELING FOR SPEECH RECOGNITION
https://arxiv.org/pdf/2005.09267.pdf

Semi-supervised ASR by End-to-end Self-training
https://arxiv.org/pdf/2001.09128.pdf

QUARTZNET: DEEP AUTOMATIC SPEECH RECOGNITION WITH 1D TIME-CHANNEL SEPARABLE CONVOLUTIONS
https://arxiv.org/pdf/1910.10261.pdf

OpenDcd - An Open Source WFST based Speech Recognition Decoder
athena-decoder
https://github.com/athena-team/athena-decoder

FRILL: A Non-Semantic Speech Embedding for Mobile Devices
https://arxiv.org/pdf/2011.04609.pdf

CONVOLUTIONAL DROPOUT AND WORDPIECE AUGMENTATION FOR END-TO-END SPEECH RECOGNITION
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9415004&tag=1

Leveraging Pre-trained Checkpoints for Sequence Generation Tasks
https://arxiv.org/pdf/1907.12461.pdf

Improving Pre-Trained Multilingual Models with Vocabulary Expansion
https://aclanthology.org/K19-1030.pdf

∆LM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders
https://arxiv.org/pdf/2106.13736.pdf

Training Tips for the Transformer Model
https://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf

DEVELOPING REAL-TIME STREAMING TRANSFORMER TRANSDUCER FOR SPEECH RECOGNITION ON LARGE-SCALE DATASET
https://arxiv.org/pdf/2010.11395.pdf

ADVANCING ACOUSTIC-TO-WORD CTC MODEL
https://arxiv.org/pdf/2102.03216.pdf

Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling

STATE-OF-THE-ART SPEECH RECOGNITION WITH SEQUENCE-TO-SEQUENCE MODELS
https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/74a8df45b9583e193e6cf8e156dfba9b73c33a0c.pdf

INTERMEDIATE LOSS REGULARIZATION FOR CTC-BASED SPEECH RECOGNITION
https://arxiv.org/pdf/2102.03216.pdf

Improving Pre-Trained Multilingual Models with Vocabulary Expansion
https://aclanthology.org/K19-1030.pdf

wav2vec: Self-supervised learning of speech representations
https://michaelauli.github.io/talks/wav2vec-ssl.pdf

KT-Speech-Crawler: Automatic Dataset Construction for Speech Recognition from YouTube Videos
https://arxiv.org/pdf/1903.00216.pdf

Multi-Stride Self-Attention for Speech Recognition
https://www.isca-speech.org/archive/pdfs/interspeech_2019/han19b_interspeech.pdf

LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition
https://arxiv.org/pdf/2008.03687.pdf

VOXLINGUA107: A DATASET FOR SPOKEN LANGUAGE RECOGNITION
https://arxiv.org/pdf/2011.12998.pdf

BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition
https://arxiv.org/pdf/2109.13226.pdf

An Empirical Study of Training Self-Supervised Vision Transformers
https://arxiv.org/pdf/2104.02057.pdf

EFFICIENT CONFORMER: PROGRESSIVE DOWNSAMPLING AND GROUPED ATTENTION FOR AUTOMATIC SPEECH RECOGNITION

Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition
https://arxiv.org/pdf/2010.10504v1.pdf

Wav2vec-C: A Self-supervised Model for Speech Representation Learning
https://arxiv.org/pdf/2103.08393.pdf

∆LM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders
https://arxiv.org/pdf/2106.13736.pdf

W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training
https://arxiv.org/abs/2108.06209

LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition
https://arxiv.org/pdf/2008.03687.pdf

ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification
https://arxiv.org/pdf/2005.07143.pdf

INCREMENTAL LEARNING FOR END-TO-END AUTOMATIC SPEECH RECOGNITION
https://arxiv.org/pdf/2005.04288.pdf

ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context
https://arxiv.org/pdf/2005.03191.pdf

WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing
https://arxiv.org/pdf/2110.13900.pdf

HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units
https://arxiv.org/pdf/2106.07447.pdf

BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition
https://arxiv.org/pdf/2109.13226.pdf

Efficient minimum word error rate training of RNN-Transducer for end-to-end speech recognition
https://arxiv.org/pdf/2007.13802.pdf

Rethinking the Inception Architecture for Computer Vision
https://arxiv.org/pdf/1512.00567.pdf

MulDA: A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual NER
https://aclanthology.org/2021.acl-long.453.pdf

Multilingual Transfer Learning for QA Using Translation as Data Augmentation

Simple Data Augmentation for Multilingual NLU in Task Oriented Dialogue Systems

文本分类
Improving BERT-Based Text Classification With Auxiliary Sentence and Domain Knowledge

METRICS FOR MULTI-CLASS CLASSIFICATION: AN OVERVIEW
https://arxiv.org/pdf/2008.05756.pdf

https://topic.atatech.org/articles/181105
NLP小样本问题+多模型实时链路in高德出行人身安全管控项目

RoBERTa-wwm-ext Fine-Tuning for Chinese Text Classification
https://arxiv.org/pdf/2103.00492.pdf

Unsupervised Data Augmentation for Consistency Training
https://arxiv.org/pdf/1904.12848.pdf

WeNet 更新：支持时间戳
https://zhuanlan.zhihu.com/p/367217380

Large-scale, sequence-discriminative, joint adaptive training for masking-based robust ASR
https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/44019.pdf

PyTorch 源码解读之 BN & SyncBN：BN 与 多卡同步 BN 详解
https://mp.weixin.qq.com/s/Hq1vkvxZDuOLkAqDX_6dNQ

阿里陈克寒：实时语音场景下的智能对话
https://mp.weixin.qq.com/s/80qAiVENokPLK16LKsS-lg

Using Synthetic Audio to Improve the Recognition of Out-of-Vocabulary Words in End-to-End Asr Systems
https://yuque.antfin-inc.com/ai-live/ogyr57/xvg2ic

LARGE-SCALE ASR DOMAIN ADAPTATION USING SELF- AND SEMI-SUPERVISED LEARNING

Data Efficient Masked Language Modeling for Vision and Language
https://arxiv.org/pdf/2109.02040.pdf
建议多mask content words

UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING
https://arxiv.org/pdf/2110.05752.pdf

Recent Advances in End-to-End Automatic Speech Recognition
https://arxiv.org/pdf/2111.01690.pdf

SELF-SUPERVISED LEARNING FOR SPEECH RECOGNITION WITH INTERMEDIATE LAYER SUPERVISION
https://arxiv.org/pdf/2112.08778.pdf

https://github.com/s3prl/s3prl

EFFICIENT ADAPTER TRANSFER OF SELF-SUPERVISED SPEECH MODELS FOR AUTOMATIC SPEECH RECOGNITION
https://arxiv.org/pdf/2202.03218.pdf

LEARNING WORD-LEVEL CONFIDENCE FOR SUBWORD END-TO-END ASR
https://arxiv.org/pdf/2103.06716.pdf

LARGE-SCALE ASR DOMAIN ADAPTATION USING SELF- AND SEMI-SUPERVISED LEARNING
https://arxiv.org/pdf/2110.00165.pdf

Efficient minimum word error rate training of RNN-Transducer for end-to-end speech recognition
https://arxiv.org/pdf/2007.13802.pdf

CONTRASTIVE SEMI-SUPERVISED LEARNING FOR ASR
https://arxiv.org/pdf/2103.05149.pdf

JOINT MASKED CPC AND CTC TRAINING FOR ASR
https://arxiv.org/pdf/2011.00093v2.pdf

RepVGG:https://zhuanlan.zhihu.com/p/344324470

On Generative Spoken Language Modeling from Raw Audio

Self-supervised learning with random-projection quantizer for speech recognition

RepVGG: Making VGG-style ConvNets Great Again

Masked Autoencoders Are Scalable Vision Learners

Res2Net: A New Multi-scale Backbone Architecture

VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION

On Generative Spoken Language Modeling from Raw Audio

经典CNN网络解析
https://zhuanlan.zhihu.com/p/192835137

为什么Transformer要用LayerNorm？
https://www.zhihu.com/question/487766088

Res2Net阅读笔记
https://zhuanlan.zhihu.com/p/92102692

CNN模型之SqueezeNet
https://zhuanlan.zhihu.com/p/31558773

DenseNet：比ResNet更优的CNN模型
https://zhuanlan.zhihu.com/p/37189203

AM-Softmax
https://zhuanlan.zhihu.com/p/85252097

The SpeakIn System for VoxCeleb Speaker Recognition Challange 2021

Y-Vector: Multiscale Waveform Encoder for Speaker Embedding

UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data

RepVGG：极简架构，SOTA性能，让VGG式模型再次伟大（CVPR-2021）
https://zhuanlan.zhihu.com/p/344324470

On Generative Spoken Language Modeling from Raw Audio

全局平均池化（Global Average Pooling）
https://zhuanlan.zhihu.com/p/164716705

Federated Domain Adaptation for ASR with Full Self-Supervision
https://arxiv.org/pdf/2203.15966.pdf

EMFORMER: EFFICIENT MEMORY TRANSFORMER BASED ACOUSTIC MODEL FOR LOW LATENCY STREAMING SPEECH RECOGNITION
https://arxiv.org/pdf/2010.10759.pdf

Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data
https://arxiv.org/pdf/2203.17113.pdf

4-bit Conformer with Native Quantization Aware Training for Speech Recognition
https://arxiv.org/pdf/2203.15952.pdf

CONSISTENT TRAINING AND DECODING FOR END-TO-END SPEECH RECOGNITION USING LATTICE-FREE MMI

Unsupervised Data Selection via Discrete Speech Representation for ASR

mSLAM: Massively multilingual joint pre-training for speech and text

Large-scale ASR Domain Adaptation using Self- and Semi-supervised Learning

Speech Pre-training with Acoustic Piece

Self-supervised learning with random-projection quantizer for speech recognition

A STUDY OF TRANSDUCER BASED END-TO-END ASR WITH ESPNET: ARCHITECTURE, AUXILIARY LOSS AND DECODING STRATEGIES

CASCADED ENCODERS FOR UNIFYING STREAMING AND NON-STREAMING ASR
https://arxiv.org/pdf/2010.14606.pdf

FASTEMIT: LOW-LATENCY STREAMING ASR WITH SEQUENCE-LEVEL EMISSION REGULARIZATION
https://arxiv.org/pdf/2010.11148.pdf

Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data
https://arxiv.org/pdf/2205.08014.pdf

UNIVERSAL PARALINGUISTIC SPEECH REPRESENTATIONS USING SELF-SUPERVISED CONFORMERS
https://arxiv.org/pdf/2110.04621.pdf

JOINT UNSUPERVISED AND SUPERVISED TRAINING FOR MULTILINGUAL ASR
https://arxiv.org/pdf/2111.08137.pdf

LESS IS MORE: IMPROVED RNN-T DECODING USING LIMITED LABEL CONTEXT AND PATH MERGING
https://arxiv.org/pdf/2012.06749.pdf

A BETTER AND FASTER END-TO-END MODEL FOR STREAMING ASR
https://arxiv.org/pdf/2011.10798.pdf

Tied & Reduced RNN-T Decoder
https://arxiv.org/pdf/2109.07513.pdf

IMPROVING THE LATENCY AND QUALITY OF CASCADED ENCODERS
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9747879

RNN-T MODELS FAIL TO GENERALIZE TO OUT-OF-DOMAIN AUDIO: CAUSES AND SOLUTIONS
https://arxiv.org/pdf/2005.03271.pdf

HYBRID RNN-T/ATTENTION-BASED STREAMING ASR WITH TRIGGERED CHUNKWISE ATTENTION AND DUAL INTERNAL LANGUAGE MODEL INTEGRATION
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746428

IMPROVING THE FUSION OF ACOUSTIC AND TEXT REPRESENTATIONS IN RNN-T
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9747418

An Efficient Streaming Non-Recurrent On-Device End-to-End Model with Improvements to Rare-Word Modeling
https://www.isca-speech.org/archive/pdfs/interspeech_2021/sainath21_interspeech.pdf

A BETTER AND FASTER END-TO-END MODEL FOR STREAMING ASR
https://arxiv.org/pdf/2011.10798.pdf

Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data
https://arxiv.org/pdf/2205.08014.pdf

UNIVERSAL PARALINGUISTIC SPEECH REPRESENTATIONS USING SELF-SUPERVISED CONFORMERS
https://arxiv.org/pdf/2110.04621.pdf

JOINT UNSUPERVISED AND SUPERVISED TRAINING FOR MULTILINGUAL ASR
https://arxiv.org/pdf/2111.08137.pdf

RNN-T MODELS FAIL TO GENERALIZE TO OUT-OF-DOMAIN AUDIO: CAUSES AND SOLUTIONS
https://arxiv.org/pdf/2005.03271.pdf

Pruned RNN-T for fast, memory-efficient ASR training
https://arxiv.org/pdf/2206.13236.pdf 

HAVE BEST OF BOTH WORLDS: TWO-PASS HYBRID AND E2E CASCADING FRAMEWORK FOR SPEECH RECOGNITION
https://arxiv.org/pdf/2110.04891.pdf

CONTINUOUS STREAMING MULTI-TALKER ASR WITH DUAL-PATH TRANSDUCERS
https://arxiv.org/pdf/2109.08555.pdf

SELF-SUPERVISED LEARNING FOR SPEECH RECOGNITION WITH INTERMEDIATE LAYER SUPERVISION
https://arxiv.org/pdf/2112.08778.pdf

TRANSDUCER-BASED STREAMING DELIBERATION FOR CASCADED ENCODERS
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746406

DELIBERATION OF STREAMING RNN-TRANSDUCER BY NON-AUTOREGRESSIVE DECODING
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746390

JOINT UNSUPERVISED AND SUPERVISED TRAINING FOR MULTILINGUAL ASR
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746038

IMPROVING THE FUSION OF ACOUSTIC AND TEXT REPRESENTATIONS IN RNN-T
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9747418

MASSIVELY MULTILINGUAL ASR: A LIFELONG LEARNING SOLUTION
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746594

Conformer-based End-to-end Speech Recognition With Rotary Position Embedding

UNSUPERVISED MODEL ADAPTATION FOR END-TO-END ASR

RETHINKING EVALUATION IN ASR: ARE OUR MODELS ROBUST ENOUGH?

Does Knowledge Help General NLU? An Empirical Study

Neural Data Augmentation via Example Extrapolation

Dialogue State Tracking with a Language Model using Schema-Driven Prompting

STUDYING SQUEEZE-AND-EXCITATION USED IN CNN FOR SPEAKER VERIFICATION

PromDA: Prompt-based Data Augmentation for Low-Resource NLU Tasks

CROSS-ATTENTION CONFORMER FOR CONTEXT MODELING IN SPEECH ENHANCEMENT FOR ASR

Effective Attention-Based Sequence-to-Sequence Modelling for Automatic Speech Recognition

Efficient Conformer with Prob-Sparse Attention Mechanism for End-to-End Speech Recognition

Deep Sparse Conformer for Speech Recognition

Rethinking Attention with Performers

Edit Distance based RL for RNNT decoding

Mixture-of-Expert Conformer for Streaming Multilingual ASR

mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations
